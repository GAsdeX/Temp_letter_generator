[
  {
    "applicationUID": "826183400869355520",
    "openingUID": "826182940630294528",
    "coverLetter": "Hello Eivind Semb,\n\nThank you for reaching me out. I've recently created a bunch of scrappers including the required functionality:\n- scrapping yellowpages;\n- finding contact page(s) on company website(s);\n- finding emails.\nFinding company twitter and looking for email there also can be helpful.\nPossible solutions are Chrome extension or PHP script.\n\nI can start immediately and prove the concept within a day.\nThe entire development will take 3 days for programming and 3-5 days for testing.\nMy skype: promios\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "831282792630288384",
    "openingUID": "831282121029644288",
    "coverLetter": "Hi David,\n\nThank you for reaching me out.\n\nI don't use Perl but having a strong background in web scraping, including my work as a CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed it on a dashboard.\n\nI've implemented about 50 scrappers, I know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nI'm living in Ukraine now, spent about a month in Mountain View \/ SF last fall.\n8am-3pm PST is a good working time for me.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "829823766809649152",
    "openingUID": "829822493094158336",
    "coverLetter": "Hello,\n\nThank you for reaching me out. I'm interested and ready to sign an NDA to learn the details.\n\nBest,\nRinat"
  },
  {
    "applicationUID": "827564210695872512",
    "openingUID": "827562802444083200",
    "coverLetter": "Hello Joe,\n\nThanks a lot for reaching me out. Unfortunately, the project seems too complicated for the budget. Is it negotiable?\nOr, probably, we can simplify it and implement some performance improvements later?\n\nI've implemented about 10 projects using phantomjs now. Few words about my scraping experience...\nI have a relevant experience in crawling\/scrapping sites and about 13 years experience in web development.\nI worked about 2 years as a CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed on a dashboard.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nMy skype is: promios\nPlease ping me if you have any questions.\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "801672227344510976",
    "openingUID": "801472281326022656",
    "coverLetter": "Hello Amiram,\n\nThanks for reaching me out.\nI'm Rinat from Ukraine. My skype: promios\nI have 13 years experience in full stack web development, strong JS background including JS sellable extensions development. The closest of existing projects I've implemented is http:\/\/avenu.ua\/ua\/calc\/ - the pavement placement calculator. However, it used Flash\/AS3 and I would prefer js\/canvas for the new application. I also developed a furniture placement calculator about 5 years ago but that business and site are closed now.\n\nI don't see any difficulties in the proposed workflow diagram, this just has to be done. We could use one of the existing PHP frameworks for backend and user registration and create the kitchen calculator frontend using JS&Canvas.\n\nI have a couple questions:\n1. The workflow diagram: what is \"AR\" in the \"Preview (AR)\" stage?\n2. Will you provide the design or this is required from my side?\n\nI can start immediately. The kitchen app will take about a week. The entire project terms will depend on your answers.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "794782983629340672",
    "openingUID": "794766867256627200",
    "coverLetter": "Hello Henrik Friis Juhl,\n\nThanks for reaching me out.\nI'm Rinat from Ukraine, having about 13 years background in full stack web development. Some of my latest projects:\nhttp:\/\/luxurylifestyleawards.com\/\nhttp:\/\/www.fcdnipro.ua\/en\/index\/\nI'm familiar with material design and can start immediately.\n\nThanks,\n\nBest regards,\nRinat Gilmutdinov"
  },
  {
    "applicationUID": "829995603463598080",
    "openingUID": "829995327372238848",
    "coverLetter": "Hello Lloyd,\n\nThanks. Please approve the job and I'll start shortly.\nSure, we can run it once a week, but I'll probably ask you for some extra fee for doing this. It depends on how protected offshorestaffing.com is, I will learn more about their protection scrapping it.\n\nBest,\nRinat"
  },
  {
    "applicationUID": "827503956293492736",
    "openingUID": "827503698400878592",
    "coverLetter": "Hello Christian,\n\nThank you for reaching me out.\nI'm able to start in 6 hours.\n\nI have a relevant experience in crawling\/scrapping sites and about 13 years experience in web development.\nI worked about 2 years as a CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed on a dashboard.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my previous scrappers:\nLinkedin user profiles and company pages;\nbackpage, idealist, indeed and craigslist crawling for emails;\ncrawling autotrader, raccars, vcars, driving, piston and some other UK automotive sites;\nscrapping of ~700k records from yellowpages.com;\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nyell.com crawling to get companies contact data;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "814216575520444416",
    "openingUID": "814184230712406016",
    "coverLetter": "Hello Sam,\n\nThank you for reaching me out. Your proposal sounds interesting and relevant to my experience. I have an active project at the moment but would be happy to discuss the details.\n\nBest,\nRinat"
  },
  {
    "applicationUID": "817294844599832576",
    "openingUID": "817294379459178496",
    "coverLetter": "Hi,\nWill implement this today.\nThanks"
  },
  {
    "applicationUID": "816266737002352640",
    "openingUID": "816265783319531520",
    "coverLetter": "Hello Marty,\n\nThank you for reaching me out.\nI'm Rinat from Ukraine, having about 13 years experience in full stack web development, including WP websites and plugins.\nI can start tomorrow.\n\nBest,\nRinat"
  },
  {
    "applicationUID": "814252770352566272",
    "openingUID": "814252425297162240",
    "coverLetter": "Hello Nick,\n\nThank you for reaching me out.\n\nI have a relevant experience in crawling\/scrapping sites and about 13 years experience in web development.\nI worked about 2 years as a CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed on a dashboard.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my previous scrappers:\nLinkedin user profiles and company pages;\nbackpage, idealist, indeed and craigslist crawling for emails;\ncrawling autotrader, raccars, vcars, driving, piston and some other UK automotive sites;\nscrapping of ~700k records from yellowpages.com;\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nyell.com crawling to get companies contact data;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "788375481054863360",
    "openingUID": "788372950396059648",
    "coverLetter": "Hi Richard,\n\nThank you for reaching me out.\nI'm Rinat from Ukraine. My skype ID is: promios\n\nI have a relevant experience in crawling\/scrapping sites and about 13 years experience in web development. The most relevant is my experience at the position of CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed it on a dashboard. One of our pivots was a news aggregator, so I understand the subject very well.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my other previous crawlers\/scrappers are:\nbackpage, idealist, indeed and craigslist crawling for emails;\ncrawling autotrader, raccars, vcars, driving, piston and some other UK automotive sites;\nscrapping of ~700k records from yellowpages.com;\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nyell.com crawling to get companies contact data;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nThe news aggregator will cost $300.\nI can start immediately and prove the concept within one day. The development will take up to 6 days: 2 days for development + 4 days for testing and debug.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "795018101141692416",
    "openingUID": "794983030284668928",
    "coverLetter": "Hi,\n\nI have recently developed few projects for LinkedIn automation. They allowed to automate connections, saved multiple profiles to CSV, looked for emails, scrapped company data etc. I didn't use LinkedIn API. I spent few months to bypass LinkedIn multilevel protection and avoid bans.\n\nI also have a relevant experience in scrapping sites and about 13 years experience in full-stack web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nI can start immediately to prove the concept.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "795410544672530432",
    "openingUID": "795334080413003776",
    "coverLetter": "Hi,\n\nI have recently scrapped http:\/\/www.yellowpages.com\/, so I can complete it within 4-6 hours: 2 hours for development & adjustment and 2-4 hours for waiting when scrapping is complete.\nPlease pay attention, only some companies have emails on yellowpages.com. More emails could be found using more complicated scrapping algorithm.\n\nI also have a relevant experience in scrapping sites and about 13 years experience in full-stack web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nI can start immediately.\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "801115797437517824",
    "openingUID": "801059832851476480",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine :) My skype ID is: promios\n\nI have a relevant experience in crawling\/scrapping sites and about 13 years experience in web development.\nI worked about 2 years as a CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed on a dashboard.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my previous scrappers:\nLinkedin user profiles and company pages;\nbackpage, idealist, indeed and craigslist crawling for emails;\ncrawling autotrader, raccars, vcars, driving, piston and some other UK automotive sites;\nscrapping of ~700k records from yellowpages.com;\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nyell.com crawling to get companies contact data;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI can start immediately to prove the concept.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "796296424348676096",
    "openingUID": "796197177164001280",
    "coverLetter": "Hello Frank,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI have a relevant experience in crawling\/scrapping sites and about 13 years experience in web development.\nI worked about 2 years as a CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed on a dashboard.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nAnswers:\nI use php CURL \/ phantomjs \/ chrome extensions for scrapping.\nProbably I developed about 150-200 scrappers. Hard to say.\nI'm familiar with using proxy servers. Including gray servers with all their problems.\nThe most difficult scrappers were Elance and LinkedIn.\nMy typical rate is $30\/hr for small jobs, negotiable for long term relationship.\n\nSome of my previous scrappers:\nLinkedin user profiles and company pages;\nbackpage, idealist, indeed and craigslist crawling for emails;\ncrawling autotrader, raccars, vcars, driving, piston and some other UK automotive sites;\nscrapping of ~700k records from yellowpages.com;\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nyell.com crawling to get companies contact data;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "798996714104856576",
    "openingUID": "798994339432902656",
    "coverLetter": "Hi Marty,\n\nThank you for reaching me out. That is true, I really know how to make wordpress site SSL-compatible.\nWe have at least 2 ways:\n1. Review WP options and all plugins and check all settings. OR\n2. Add replacement function and use caching plugin (if not used yet).\n\nEach of above methods has its pros and cons, need to review site to propose an optimal solution.\nI can start immediately.\n\nThanks,\n\nRegards,\nRinat"
  },
  {
    "applicationUID": "796298231731372032",
    "openingUID": "796210274554400768",
    "coverLetter": "Hello,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI can start immediately and complete it within 24 hours.\n\nI have a relevant experience in crawling\/scrapping sites and about 13 years experience in web development.\nI worked about 2 years as a CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed on a dashboard.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my previous scrappers:\nLinkedin user profiles and company pages;\nbackpage, idealist, indeed and craigslist crawling for emails;\ncrawling autotrader, raccars, vcars, driving, piston and some other UK automotive sites;\nscrapping of ~700k records from yellowpages.com;\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nyell.com crawling to get companies contact data;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "795023604675211264",
    "openingUID": "794940596041338880",
    "coverLetter": "Hi,\n\nI have recently developed few projects for LinkedIn automation, including email scrapping and detection. I spent few months to bypass LinkedIn multilevel protection and avoid bans.\nI used PING to detect even undefined emails when website was defined. We can use ping for initial email verification or use multi-level verification.\n\nI also have a relevant experience in scrapping sites and about 13 years experience in full-stack web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nI worked about 2 years as a CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed it on a dashboard.\n\nHaving a question:\nDo you have some additional requirements?\nFor example:\n- It should work on server\n- It should scrap 1000 emails daily\n\nI can start immediately to prove the concept.\nMy skype is: promios\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "757945244601622528",
    "openingUID": "757906762870800384",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI have a relevant experience in scrapping sites and about 13 years experience in web development.\nI worked as a CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed on a dashboard.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nI can start immediately and prove the concept within one day.\n\nCheers,\nRinat"
  },
  {
    "applicationUID": "779304523132248064",
    "openingUID": "779304120508354560",
    "coverLetter": "Hello Mark,\n\nThank you for reaching me out.\nPlease let me know the store link where the sneakers will be released?\nI need this to try placing a test order for better understanding, what will we need to do.\n\nThanks,\nBest,\nRinat"
  },
  {
    "applicationUID": "751272956337385472",
    "openingUID": "745214216659623936",
    "coverLetter": "Hello,\n\nThank you for reaching me out. Your proposal looks interesting for me and yes, it good fits with my skills, I work with front-ends since 2002.\nMy skype id: promios. Please let me know what time best works for you to have a chat?\nThanks,\n\nBest regards,\nRinat Gilmutdinov"
  },
  {
    "applicationUID": "769652884472553472",
    "openingUID": "768687167215558656",
    "coverLetter": "Hi,\n\nI have recently developed few projects for LinkedIn automation. They allowed to automate connections, saved multiple profiles to CSV, looked for emails, scrapped company data etc. I didn't use LinkedIn API. I spent few months to bypass LinkedIn multilevel protection and avoid bans.\n\nI also have a relevant experience in scrapping sites and about 13 years experience in full-stack web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nI worked about 2 years as a CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed it on a dashboard.\n\nI can start immediately to prove the concept.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "768787559529435136",
    "openingUID": "768755115502395392",
    "coverLetter": "Hi,\n\nThe example is attached.\nThis will take 4 working hours ($120) to create the scrapper and up to 3 days to grab the data.\n\nPlease keep in mind that we should split the search results to get all 450k of items, now they are limited by 5005 items per listing, for example:\nhttp:\/\/www.houzz.com\/professionals\/interior-designer\/p\/15000\n(see \"Only the top 5005 items are presented\" at the bottom of the page)\nAnd we should also scrap each page to get Contact Names and split scrapping in a few threads to complete it in time.\n\nI have a huge scraping experience and about 13 years in web development. I can start immediately and complete this job in required 3 days.\n\nThanks,\nBest regards,\nRinat"
  },
  {
    "applicationUID": "757743693940744192",
    "openingUID": "757160463747342336",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI have about 13 years experience in full cycle web development, including Nuzic.net audio\/video streaming service for artists & DJs. The project is currently closed. The backend was based on jamroom and used ffmpeg for video editing. I worked both with server-side and client interfaces.\n\nPlease contact me on upwork chat or skype, curious to learn more about your project.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "775889216269946880",
    "openingUID": "772910343154589696",
    "coverLetter": "Hello Alejandro,\n\nThank you for reaching me out.\nIs this job some kind of automatic posting to quora-like site, or you need this to be done manually?\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "757511516602462208",
    "openingUID": "757060719976996864",
    "coverLetter": "Hi,\n\nI'm a good fit for this project since I have recently developed the chrome extension with close functionality (see below).\n\nI'm also familiar with server side (the database part), have 12 years experience in web development, developed few chrome extensions and know how to publish the extension on google play.\n\nPlease answer:\nWill you develop promo materials (images, video, description) by yourself, or they are supposed to be included in this job? Or this is a further step?\n\nI can start immediately and prove the concept within one day.\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "768818039999655936",
    "openingUID": "768806528562257920",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine :)\nI have scrapped yell.com before, can start immediately and complete this task in 1 day. Please let me know the categories\/URLs.\nI have a huge scrapping experience and about 13 years background in web development.\nMy skype: promios\n\nThanks,\nBest regards,\nRinat"
  },
  {
    "applicationUID": "773155809982001152",
    "openingUID": "773155348302848000",
    "coverLetter": "Hello Yaw,\n\nThank you for reaching me out.\nI've created something similar shortly, it grabbed the data from twitter, added it and reposted to twitter. Please let me know the target (second) social network, and I'll assess the time.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "757783908084174848",
    "openingUID": "757771655322886144",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nMy development experience is 13 years. The most relevant for this project is my work as a CTO at Periodix.net startup (2 years). I've created a chrome extension, that allows to take any part of any site and update it on your dashboard. I know all the nuances of extension development and teamwork, including documentation, NDA, testing, google play publication...\n\nI can start immediately and prove the concept within one day.\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "757951530000011264",
    "openingUID": "757938322441486336",
    "coverLetter": "Hello Frank,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI have a relevant experience in crawling\/scrapping sites and about 13 years experience in web development.\nI worked about 2 years as a CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed on a dashboard.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nI can start immediately and prove the concept within one day.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "768880707660271616",
    "openingUID": "768836262310469632",
    "coverLetter": "Hello,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI have a relevant experience in crawling\/scrapping sites and about 13 years experience in web development.\nI have created few products for scrapping data from craigslist (among others) before.\nI also worked about 2 years as a CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed it on a dashboard.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nI can start immediately and prove the concept within one day. The development will take up to 6 days: 3 days for development + 3 days for testing and debug.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "757656042694815744",
    "openingUID": "757649097458016256",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine.\nMy skype ID is: promios\nICQ: 210468224\n\nI have a relevant experience in crawling sites and emulating user activity using curl and phantomjs, including my 2 years work at Periodix.net startup - it crawls various sites and places the data to user dashboard.\nI also implemented tens of private crawling projects for the last time, using chrome extensions, curl, phantomjs, phantomjscloud.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load etc. My web development experience is 13 years.\n\nI worked with NDAs before, please send me your version of the NDA - I will sign it and send you a scan.\n\nI can start immediately to prove the concept.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "758073316960194560",
    "openingUID": "758057019585421312",
    "coverLetter": "Hello Joseph,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI have a relevant experience in crawling\/scrapping sites, including ebay, amazon and about 15 other stores.\nI have about 13 years experience in web development and worked for 2 years as a CTO at Periodix.net startup, that scraped data from various (user defined) sites and displayed it on dashboards.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my other previous crawlers\/scrappers are:\ncrawling autotrader, raccars, vcars, driving, piston and some other UK automotive sites;\nscrapping of ~700k records from yellowpages.com;\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\nYou can find some of my scrapper jobs and customers' feedback on my upwork profile.\n\nI can start immediately to prove the concept.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "759057646872518656",
    "openingUID": "759053244828835840",
    "coverLetter": "Hello Frank,\n\nI have received 2 same invitations to the interview from you. I will accept one and decline another.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "757942567569281024",
    "openingUID": "757915795853918208",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI recently developed a crawler that allows finding LinkedIn emails automatically. So, I probably can complete this job in one day. What kind of users are you looking for? Could you provide me a sample search criteria?\n\nI have a relevant experience in scrapping sites and about 13 years experience in web development.\nSome of my other previous scrappers are:\ncrawling autotrader, raccars, vcars, driving, piston and some other UK automotive sites;\nscrapping of ~700k records from yellowpages.com;\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI can start immediately.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "757953743658229760",
    "openingUID": "757951145792819200",
    "coverLetter": "Hello Joseph,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI can start immediately and complete this job within 24 hours, I think. Please provide me the site URL and I will make sure this is 100% possible.\n\nI have a relevant experience in crawling\/scrapping sites and about 13 years experience in web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my other previous crawlers\/scrappers are:\ncrawling autotrader, raccars, vcars, driving, piston and some other UK automotive sites;\nscrapping of ~700k records from yellowpages.com;\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\nYou can find some of my scrapper jobs and customers' feedback on my upwork profile.\n\nThanks,\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "757528793985019904",
    "openingUID": "757521909905956864",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI have recently developed a yellowpages.com.au scrapper. It scrapped data by the list of yellowpages URLs.\nCould you provide more information, what kind of data would you like to collect? Do you need the data or the scrapper itself?\n\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my other previous scrappers are:\ncrawling autotrader, raccars, vcars, driving, piston and some other UK automotive sites;\nscrapping of ~700k records from yellowpages.com;\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI can start immediately to prove the concept.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "732575910259208192",
    "openingUID": "732538382176321536",
    "coverLetter": "Hi,\n\nThis job is perfect for me because I've recently developed a linkedin scrapping extension for chrome.\n\nHowever, if you are using free or free trial linkedin account, linkedin bans you even when you are viewing profiles manually. Usually, it suspends your account till the end of the day, then you can scrap the data again.\n\nIn my experience, the best way to ping emails is using paid API or own server.\n\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my other previous scrappers are:\ncrawling autotrader, raccars, vcars, driving, piston and some other UK automotive sites;\nscrapping of ~700k records from yellowpages.com;\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI can start immediately to prove the concept.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "743738509848829952",
    "openingUID": "743466394694553600",
    "coverLetter": "Hi Joseph,\n\nNice meeting you again. I have reviewed the job description, I am interested and it looks feasible in general, however I will ask you few questions shortly to clarify some details.\nI'm away now and will be available in 4-5 hours.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "727880897681874944",
    "openingUID": "727853529929801728",
    "coverLetter": "Hello,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI have a relevant experience - simulated the user actions (login, fill the forms, get the data) during my work at Periodix.net startup.\n\nPlease let me know more - what is the site, what message would you like to send? What is the goal - i.m. would you like to create a web application or browser extension? ...and I will make more precise assessment.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load etc.\n\nI can start immediately to prove the concept.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "731212533670752256",
    "openingUID": "731152690593681408",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI have a relevant experience in crawling sites and emulating user activity in phantomjs, that is my 2 years work at Periodix.net startup - it crawls various sites and places the data to user dashboard. I also implemented 5 small projects with phantomjs & phantomjscloud.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc. My web development experience is 12 years.\n\nI can start immediately to prove the concept.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "727771176494620672",
    "openingUID": "727746129577304064",
    "coverLetter": "Hi Andrew,\n\nThanks for reaching me out. Could you provide the existing script and the url you are going to inject the script to?\nCurious, what are 1-2 hours for? Is something else required to be implemented, or just js code that works in url?\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "722952284195225600",
    "openingUID": "722931829827911680",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nCould you provide the sample PDFs? I mean:\n1. PDF before extension button clicked.\n2. PDF after extension applied.\nThat is important for understanding what kind of PDF transformation is required.\n\nI have both experience with chrome extensions and with pdf online generation\/formatting.\nI also have more than 12 years experience in web development.\nWould be happy to start immediately to prove the concept. See more details below.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "727784068431503360",
    "openingUID": "727760763367383040",
    "coverLetter": "Hello,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI have implemented a very close task before, finding and verifying addresses for Australian plumbing company's mobile application.\nWe could also use Google Maps API to increase the address recognition quality.\n\nPlease let me know if the design for Google Play market publication is also required.\n\nI can start immediately to prove the concept (finding\/highlighting addresses on pages) and complete this job in one week.\n\nMy web development experience is 12 years. The most relevant to this project is my work at Periodix.net startup (2 years). I've created a chrome extension that injected javascript and added page elements (among other features). I know how to create an extension from scratch, including google play publication.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "722922819968794624",
    "openingUID": "722911652779278336",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI have a wide experience scrapping automotive sites including autotrader and I can start immediately.\nWhat kind of login or web interface are you going to implement? I would like to know this to make more precise project assessment.\n\nI think, simple LAMP server and CURL is enough in our case. I know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\nI also know how to scrap data from bot-protected sites like craigslist or d.co.il in multiple threads, using proxies.\n\nSome of my other previous scrappers are:\ncrawling autotrader, raccars, vcars, driving, piston and some other UK automotive sites;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nscrapping of ~700k records from yellowpages.com;\nd.co.il complete crawling of company data;\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "723018420756643840",
    "openingUID": "722967874017665024",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nPlease answer:\n1. Are design, description and google play publication required for this extension or just working solution?\n2. Please provide the links to the similar extensions you have mentioned.\n\nI have both experience with chrome extensions and with page code injection\/manipulation.\nMy development experience is 12 years. The most relevant to this project is my work at Periodix.net startup (2 years). I've created a chrome extension that injected javascript and added page elements (among other features). I know how to create an extension from scratch, including google play publication.\n\nI can start immediately to prove the concept.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "729505668396818432",
    "openingUID": "729458594997411840",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI can start immediately and complete this job in an hour for $25.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\nI also know how to scrap data from bot-protected sites like craigslist or d.co.il in multiple threads, using proxies.\n\nSome of my other previous scrappers are:\ncrawling autotrader, raccars, vcars, driving, piston and some other UK automotive sites;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nscrapping of ~700k records from yellowpages.com;\nd.co.il complete crawling of company data;\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "721931827887177728",
    "openingUID": "721909110151790592",
    "coverLetter": "Hi,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nThe spreadsheet with the sample data is attached.\nI have scrapped yellowpages for Australia for other businesses already, able to start immediately and complete it in 3 days.\nI can send you the parts of data daily if this could be helpful.\n\nI also have a relevant experience in scrapping other sites and about 12 years experience in web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my other previous scrappers are:\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "721931843573071872",
    "openingUID": "714075656472293376",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\nWould be happy to develop the extension in 3 days.\n\nMy development experience is 12 years. The most relevant for this project is my work as a CTO at Periodix.net startup (2 years). I've created a chrome extension and server program, that allows to take any part of any site and update it on your dashboard. So, I know all the nuances, including interaction with gmail which often changes classnames, how to implement script injection via extension, not forgetting about the performance, security, google play publication...\n\nBy the way, I use rapportive extension, do you know it? :)\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "733410735894659072",
    "openingUID": "733117113177571328",
    "coverLetter": "Hi,\nThanks for reaching me out.\n\n1. Why the client should interview me...\nI'm a good fit for this project. My skills overlap with the requirements, I have 12 years experience in web development, worked a lot with designers, spent a month in Menlo Park in late 2015... I'm done with my startup, free and would like to learn more about the project.\n\n2. I meet all the \u2018must have\u2019 requirements.\nI started from Netscape 4 and IE 4 optimization, used css hacks & js tricks, developed own js library for my own CMS before jQuery appeared. I'm happy with modern browsers and html5\/css3 possibilities :) I renew my knowledge in everyday tasks, use OOP principles, canvas, browser storage, css3-amimation etc. See some of my projects below.\nI also passed upwork html5, css and js tests as top-10.\n\n3. Other 'nice-to-have\u2019 items:\nPhotoshop - 9 of 10\nIllustrator - 4 of 10, Flash - 7 of 10\nI don't know SpringMVC or Struts, I mostly deal with php (symfony, zend etc.)\nSEO - 7 of 10\nOptimizing conversion rates - 7 of 10 (Google Analytics, Mixpanel, WebVizor...)\nMySQL, Postgre, PHP - 8 of 10\nChrome Extensions Development - 7 of 10\nPhonegap & Mobile Development - 7 of 10\n\n4. Most relevant portfolio examples.\nPeriodix\nPeriodix (startup, 2015) allowed you to take any part from any site and track it on your cloud dashboard. Pivot: Periodix allowed freelancers and IT-sales to decrease their bidding time and increase their sales.\nRoles: CTO & co-founder, Backend & frontend developer, UI developer.\n\nWilco Plumbing\nWeb & Mobile applications (iOS & Android using Phonegap). Private CRM for Australian plumbing company.\nRoles: Backend & frontend developer, UI developer.\n\nFC Dnipro\nwww.fcdnipro.ua\nhttp:\/\/www.fcdnipro.ua\/ru\/match-center\/2016\/05\/07\/3788\/#online\nFootball Club's website. 1+ mln. views per month.\nRoles: Backend & frontend developer, UI developer.\n\nAstraMoney\nPaying system (startup, 2005) & side services: Referral system, Exchanger, Stock, GEO-service, Passport, PIN-shop, WAP, Forum etc. Exit in 2006.\nRoles: CTO, Coder.\n\nQwidgi\nSocial network (startup, 2008) like linkedin. Closed.\nRoles: Backend & frontend coder (team member).\n\nLuxor Management\nhttp:\/\/luxurylifestyleawards.com\nhttp:\/\/luxormanagement.net\nhttp:\/\/luxuryeducation.net etc.\n8 projects in Luxury Consulting & Communication segment.\nRoles: Backend & frontend developer, Outsource team leader.\n\nThe Funplex\nhttp:\/\/thefunplex.com\nhttp:\/\/funplexmountlaurel.com\nhttp:\/\/funplexeasthanover.com etc.\nNew Jersey Amusement Park - 7 sites.\nRoles: Outsource backend & frontend developer.\n\nMy gains:\nCTO & co-founder at Periodix, joined GrowthUp business accelerator, worked in Silicon Valley.\nDeveloped an official website of Dnipro Football Club.\nFormer CTO of paying system.\n12+ years of experience in a web development.\nFreelance experience and a good understanding of product lifecycle.\nDeveloped own ERP system (Gantt chart, tenders, notifications etc.)\nDeveloped own CMS and implemented it in 30+ projects.\n\n5. I'm an individual freelancer.\n\n6. 5am - 3pm PST is the best time for communication. I'm able to work & communicate till 6pm PST sometimes.\n\n7. I'm available 15+ hours\/week now and I can increase this time to 30+ hours\/week in 7 days.\n\nBest regards,\nRinat"
  },
  {
    "applicationUID": "721931843311910912",
    "openingUID": "714461454326657024",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI have a relevant experience in scrapping and about 12 years expreience in web development. I know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\nI also know how to scrap data from bot-protected sites like craigslist or d.co.il in multiple threads, using proxies.\nI also created a set of scrappers for price comparison service in Saudi Arabia.\n\nI can start immediately to prove the concept - scrap data from some website.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "722154592766652416",
    "openingUID": "722151446323544064",
    "coverLetter": "Hi,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nCould you show me the sample dashboard? What sites are you going to scrap?\n\nI solved a very close task during my work at Periodix startup - collected all important data in one cloud dashboard.\n\nI also have a relevant experience in scrapping sites and about 12 years experience in web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nI can start immediately to prove the concept.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "705838541327925249",
    "openingUID": "688478455026606080",
    "coverLetter": "Hello,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nhttp:\/\/www.thecatholicdirectory.com requires 2-3 working hours (billed hours) plus up to 24 hours for scrapping (free hours).\n\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\n\nMore about my crawling experience:\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years).\nSome of my other previous scrappers are:\nCrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "705838540179779586",
    "openingUID": "693900766480875520",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nCould you name the site and categories (markets) to be scrapped, please?\nIs this a one-time scrapping, or scrapper should update the results?\n\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years).\nhttps:\/\/periodix.net\/\n\nSome of my other previous scrappers are:\nCrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\nThe screenshot of one of my scrappers is attached.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nHappy to answer any questions,\nThank you,\nRinat"
  },
  {
    "applicationUID": "721931843573071873",
    "openingUID": "713502530088792064",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nCould you provide me more information, where can I take the links? Link, sign in credentials (if required).\n\nAbout by experience:\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my other previous scrappers are:\nCrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nThank you, happy to answer any questions,\n\nRegards,\nRinat"
  },
  {
    "applicationUID": "721931843573071875",
    "openingUID": "714589086971850752",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nWhat platform are you using?\n\nI have already crawled twitter during my work at periodix.net.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\nI also know how to scrap data from bot-protected sites like craigslist or d.co.il in multiple threads, using proxies.\n\nSome of my other previous scrappers are:\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nscrapping of ~700k records from yellowpages.com;\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI can start immediately to prove the concept.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "727882475009851392",
    "openingUID": "727867091968516096",
    "coverLetter": "Hello,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI've done the similar one to notify me with sound when one of my scrapping Chrome extensions generates captcha.\nI can start immediately and complete it in one day.\n\nMy web development experience is 12 years. The most relevant to this project is my work at Periodix.net startup (2 years). I've created a chrome extension that injected javascript and added page elements (among other features). I know how to create an extension from scratch, including google play publication etc.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "724998665655128064",
    "openingUID": "724980316912435200",
    "coverLetter": "Hi Alex,\n\nThank you for reaching me out. I'm Rinat from Ukraine. My skype is: promios\n\nI suppose we are talking about the stage 1 below.\n\nWhat is your approach to the job?\nMaking sites or services from scratch. Result-oriented development.\n\nDo you have any questions about the job description?\n1. You have mentioned \"people\" - please tell me more about the users and privileges? Who can create, edit, moderate content?\n2. You also specified Payment Processor integration. Please provide me more information.\n\nDo you have suggestions to make this project run successfully?\nJust to do it.\n\nWhat challenging part of this job are you most experienced in?\nFirst and third stage. 12+ years experience in web development.\n\nHow long will the project take to complete?\n10-14 days.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "727892026000859136",
    "openingUID": "727889406042382336",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI've recently implemented a similar software for appeagle and brightpearl sites.\n\nI have a relevant experience - simulated the user actions (login, fill the forms, get the data) during my work at Periodix.net startup.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load etc.\n\nI can start immediately to prove the concept and complete the task in 2 days.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "721931843573071874",
    "openingUID": "713504394956042240",
    "coverLetter": "Hi,\n\nRecently I solved a very close task during my activity as a CTO at https:\/\/periodix.net\/ startup. A Chrome extension was monitoring user activity and capturing some form data and HTML, encrypting it and sending to a remote server.\n\nWhat kind of content are you going to capture?\n\nWould be happy to chat (here or on skype), discuss the details and answer any questions. My skype is promios\n\nRegards,\nRinat"
  },
  {
    "applicationUID": "705838541327925251",
    "openingUID": "688117277473562624",
    "coverLetter": "Hi,\n\nI had a relevant experience in crawling various sites during my latest project - I was a CTO at Periodix.net startup for 2 years. We placed on Amazon EC2 and MS Azure.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nI'm about 12 years in web development.\nWould be happy to have a skype call\/chat with you. My skype ID is: promios\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "705838541327925252",
    "openingUID": "688666922650222592",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID: promios\n\nI have a relevant experience in HQ data mining. See below how would I implement this job.\nI know not only how to scrap data, but how to approve its quality.\nI spent about 2 years crawling sites at the position of CTO at Periodix.net.\nMy experience is 12 years in web development. I have a small assistance team.\n\nQuestions:\n1. What are the target countries?\n2. How will you check emails \/ phones?\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "723517629483425792",
    "openingUID": "723515806493065216",
    "coverLetter": "Hi Mary,\n\nThanks for reaching me out!\nI'm Rinat from Ukraine.\nPlease give me the link and describe what information would you like to scrap?\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "722914546246975488",
    "openingUID": "722902736449257472",
    "coverLetter": "Hi,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nI scrapped the data from Craigslist before.\nI can start immediately and complete scrapping in 48 hours for $100. I have servers and a channel to implement this.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\nI also know how to scrap data from bot-protected sites like craigslist or d.co.il in multiple threads, using proxies.\n\nSome of my other previous scrappers are:\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nscrapping of ~700k records from yellowpages.com;\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\nThe screenshot of one of my scrappers is attached.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "705838540179779587",
    "openingUID": "688059314956328960",
    "coverLetter": "Hello,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nMy experience:\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years).\n\nI'm about 12 years in web development.\n\nSome of my other previous scrappers are:\nCrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "705838540179779584",
    "openingUID": "687975165498400768",
    "coverLetter": "Hi Jessie,\n\nSorry, I was asleep. I'm available now and is online starting from Monday morning, NY time. Please write me on chat or send me the time that works for you.\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "720991608800518144",
    "openingUID": "720982248826224640",
    "coverLetter": "Hello Mark,\n\nThanks for reaching me out.\nThe crawler is possible and the usage of a remote server looks more eligible. Could you provide an access to the application? I need to capture and analyze the data it sends to the server to propose you the optimal solution and make estimates.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "834841702528098310",
    "openingUID": "714496318245171200",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nMaybe including product variations spreadsheet into the page, under the product description for example, could be more helpful? Plus 'download CSV' button. Would be happy to implement this.\n\nMy development experience is 12 years. The most relevant to this project is my work as a CTO at Periodix.net startup (2 years). I've created a chrome extension that injected javascript and added page elements (among other features). I know how to create an extension from scratch, including google play publication.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "834841702528098322",
    "openingUID": "714836878998892544",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nPlease provide me with more details about the sites you are going to crawl and the actions you are going to emulate.\n\nI have a relevant experience in crawling sites and emulating user activity in phantomjs, that is my 2 years work at Periodix.net startup - it crawls various sites and places the data to user dashboard. I also implemented 2 small projects with phantomjs.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\nI also worked with postgresql, including stored procedures, in 2 projects: startup and paying system. And I work with LAMP for 12 years.\n\nI can start immediately to prove the concept.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "834841702528098330",
    "openingUID": "714450647546789888",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI have already crawled linkedin during my work at periodix.net.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\nI also know how to scrap data from bot-protected sites like craigslist or d.co.il in multiple threads, using proxies.\n\nSome of my other previous scrappers are:\nd.co.il complete crawling of company data;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nscrapping ~700k records from yellowpages.com;\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI can start immediately to prove the concept. Complete scrapping will take up to 1 month. I have servers and a channel to implement this.\n\nThanks,\nRinat\n"
  },
  {
    "applicationUID": "834841702528098329",
    "openingUID": "714453232328572928",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nWhat sites besides linkedin are you going to scrap?\n\nI solved a very close task during my activity at https:\/\/periodix.net\/ startup - developed a Chrome extension from scratch, that was able to capture data from protected websites including linkedin, facebook etc., encrypting it and sending to a remote server.\n\nI also have a relevant experience in scrapping sites and about 12 years experience in web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my other previous scrappers are:\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI can start immediately to prove the concept, and develop+test working extension in 10 days.\n\nThanks,\nRinat"
  },
  {
    "applicationUID": "834841702528098308",
    "openingUID": "714494680541364224",
    "coverLetter": "Hi,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nThat can be done as a chrome extension or as phantomjs script.\nI can start immediately and complete it in one day..\n\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my other previous scrappers are:\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\nThe screenshot of one of my scrappers is attached.\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841702528098321",
    "openingUID": "714265060788727808",
    "coverLetter": "Hi,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nIs python required? I usually use php or phantomjs, can develop yellowpages scrapper, able to start immediately and complete it in one day.\n\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my other previous scrappers are:\nyell.com crawling to get companies contact data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ncrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\nThe screenshot of one of my scrappers is attached.\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841702528098314",
    "openingUID": "713675639273705472",
    "coverLetter": "Hi,\n\nMy favorite color is green :)\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nCould you provide me all the list of blogs? I would like to review them to make sure they all may be scrapped as I am expecting.\nIf they are ok, I can complete this job till Sunday morning (Laguna Hills time).\n\nIf you have a PHP server, I will do it as a PHP script. If not, I can do it as Chrome extension or PC console application.\n\nAbout by experience:\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my other previous scrappers are:\nCrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nThank you, happy to answer any questions,\n\nRegards,\nRinat"
  },
  {
    "applicationUID": "705838541327925253",
    "openingUID": "687042213880963072",
    "coverLetter": "Hi,\n\nI'm Rinat from Ukraine. I have a very close experience within my job as a CTO in Periodix.net startup - I know how to automate login process, simulate user actions and grab data on server-side.\nI know how to avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\nI also have other crawling experience, including facebook\/twitter sign in and posting automation, news scrapping etc. - 12 years in web development.\nI will be glad to dive into details in skype call. My skype id is promios\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "705838541327925250",
    "openingUID": "680525741213491200",
    "coverLetter": "Hi,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nMostly I use PHP+CURL+MySQL for scrappers, implementing more complex solutions if required.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "705838541327925255",
    "openingUID": "689920252663873536",
    "coverLetter": "Hi,\n\nI'm Rinat. My skype is: promios\nCould you send me the screenshots?\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "705838541327925254",
    "openingUID": "690743524682940416",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nCould you name the site and fields to be scrapped, please?\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nHappy to answer any questions,\nThank you,\nRinat"
  },
  {
    "applicationUID": "705838541327925248",
    "openingUID": "693549724316762112",
    "coverLetter": "Hello,\n\nI used Phonegap for developing a Wilco Plumbing hybrid application - iOS, Android and web versions. It allows tracking users locations in real time on Google Maps with pins. I also have experience in payments integration and 13 years experience in web development.\n\nMy skype is: promios\nHappy to chat with you and answer any questions.\n\nHave a great weekend,\nRinat"
  },
  {
    "applicationUID": "705838540179779585",
    "openingUID": "693918946041561088",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years).\nhttps:\/\/periodix.net\/\nIt was hosted on Amazon S3, further moved to Azure.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my other previous scrappers are:\nCrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nHappy to answer any questions,\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841702528098311",
    "openingUID": "687063901088124928",
    "coverLetter": "Hello,\n\nHow would I do the job: I can do a crawler to scrap most of Yoga Studios contacts (on few listings) and provide details for the rest of them (company, web site, problems in scrapping). It will grab data and continue grabbing once new Studios come.\nI have a relevant job experience: crawling emails and\/or company data based on various business directions from yell.com, google.com, craigslist.com, backpage.com etc., an example is attached.\n\nMore about my experience:\nI have an experience crawling sites during my job as a CTO at Periodix.net startup (2 years).\nAnother good example is crawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841702528098327",
    "openingUID": "688522682154663936",
    "coverLetter": "Hi,\n\nI can do this job in 4-6 hours. Could you provide more 5-10 files? I'll compare them.\nI recently had almost the same task with Polish contacts database, about 3 million records.\n\nMy email is: promios@gmail.com\nSkype: promios\n\nI have about 12 years of development experience, my background is enough to implement this job )\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841702528098312",
    "openingUID": "689527380915568640",
    "coverLetter": "J.K Rowling should write an 8th Harry Potter Book\n\nHi,\n\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nThis includes 2 years experience as a CTO at Periodix startup - scrapping various sites, including sites closed by authentication forms and stocks.\n\nSome of my other previous scrappers are:\nCrawling kickstarter, indiegogo.com to find user data;\nCrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841702528098334",
    "openingUID": "693450685635391488",
    "coverLetter": "Hello,\n\nWe can do both Android and iOS versions simultaneously using Phonegap. I used this approach developing Wilco Plumbing application, it has Android, iOS and web versions.\n\nI have a relevant experience:\n...in tracking users via GPS, messaging and push notifications, paying systems integration. I developed an application that allowed tracking users on Google Maps. And I developed a paying system with own referral program as a CTO.\nI provide a full-stack development: backend, frontend, mobile.\nI have a team of developers in Ukraine and split big projects with them.\n\nMy skype is: promios\nThank you. Happy to answer any questions.\n\nHave a great weekend,\nRinat"
  },
  {
    "applicationUID": "834841702528098316",
    "openingUID": "686700290981367808",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\nAn example of UI for my last scrapper is attached.\nI have a relevant experience - crawling emails and\/or company data based on various business directions from yell.com, google.com, craigslist.com, backpage.com etc.\n\nMore about my experience:\nI have an experience crawling sites during my job as a CTO at Periodix.net startup (2 years).\nAnother good example is crawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nHappy to have a skype chat with you.\n\nThank you,\n\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098328",
    "openingUID": "688145269439979520",
    "coverLetter": "Hi,\n\nHow many results would you like to get?\n\nI have a relevant experience in crawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nI also crawled auto portals to get data for clients sites during my previous jobs.\n\nI'm about 12 years in web development and have much more crawling experience, especially I built crawlers for last 2 hears being a CTO at Periodix.net.\n\nWould be happy to have a skype call\/chat with you. My skype ID is: promios\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841702528098323",
    "openingUID": "679953388345229312",
    "coverLetter": "Hello,\n\nNice meeting you.\nMy skype ID is: promios\n\nMy experience:\nI have a strong background in crawling sites. The most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years). Another good example is crawling Ukrainian auto sites (names are under NDA) with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nAnother reason, why is this job important for me: I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do the job quickly and in a good quality.\n\nDepending on sites and data this job will take $100-400. I can start today.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098304",
    "openingUID": "693715507437027328",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nCould you name the website to be scrapped, please?\n\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years).\nhttps:\/\/periodix.net\/\n\nSome of my other previous scrappers are:\nCrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nHappy to answer any questions,\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841702528098317",
    "openingUID": "679637852934545408",
    "coverLetter": "Hello,\n\nNice meeting you.\nMy skype ID is: promios\n\nI have a relevant experience as a CTO at Periodix.net startup (about 2 years)\nhttps:\/\/periodix.net\/cases\/purchase\n- I know how to extract data from online stores to build the comparison service. I can also build comparison service.\n\nMy other experience in crawling sites:\nCrawling Ukrainian auto sites (names are under NDA) with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098305",
    "openingUID": "681075294404747264",
    "coverLetter": "Hi,\n\nI'm Rinat from Ukraine.\nI am familiar with responsive design, html5, css3, jquery, js, ajax, php etc. and have passed some tests on upwork. I have 12 years of experience in web development, my last job was a CTO at Periodix.net startup - creating dashboards from sites parts.\n\nWhat about talking in skype? My skype id is: promios\n\nThank you\n\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098319",
    "openingUID": "686648239190089728",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nI propose to implement the job in one of this ways:\n- client js, as you described;\n- client browser extension;\n- server-side js (phantomjs etc.)\n\nThe choice depends on your goals. The most \"native\" method that allows most control is a browser extension. I'll be glad to discuss details on skype.\nI have a relevant experience - my work as a CTO at Periodix.net startup and 12 years of web development.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098332",
    "openingUID": "688065166828298240",
    "coverLetter": "Hello,\n\nI have implemented a craigslist scrapper 2 weeks ago.\n\nMy skype id: promios\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nMy experience:\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years). Incudes craigslist crawling.\n\nI'm about 12 years in web development.\n\nSome of my other previous scrappers are:\nCrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098333",
    "openingUID": "686874683275612160",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\nI have an experience in scrapping and pre-aggregating news, including scrapping google news (google alerts).\nI'm available now and would be happy doing this job in 24-hours term (more time may be required for the scrapping process).\n\nMore about my experience:\nI have an experience crawling sites during my job as a CTO at Periodix.net startup (2 years), and we started as news aggregator.\nAnother good example is crawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098325",
    "openingUID": "680629413864448000",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI propose you to make this job as a chrome extension. It will work exactly as you described. I have one question: \"email that I upload\" - did you mean email template, or it should be a custom message?\n\nAbout my experience:\nThe most relevant experience for this project is my job as a CTO at Periodix.net startup (2 years). It allows to take any part from any site, including kickstarter, and track it on your cloud dashboard.\nI know, how to simulate user actions, how to make crawlers, fake browser actions, crawl js-driven sites etc.\n\nAnother reason, why is this job important for me: I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do the job quickly and in a good quality.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098326",
    "openingUID": "679543410478686208",
    "coverLetter": "Hello,\n\nNice meeting you.\nMy skype ID is: promios\n\nMy experience:\nI have a strong background in crawling sites. The most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years). Another good example is crawling Ukrainian auto sites (names are under NDA) with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nAnother reason, why is this job important for me: I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do the job quickly and in a good quality.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098306",
    "openingUID": "672135419818385408",
    "coverLetter": ""
  },
  {
    "applicationUID": "834841702528098331",
    "openingUID": "681323069731766272",
    "coverLetter": "Hello Constantina,\n\nThank you for the invitation. I am available now.\nMy skype id: promios\n\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098315",
    "openingUID": "682645338221846528",
    "coverLetter": "Hello,\n\nNice meeting you.\nI'm Rinat from Ukraine. My skype ID is: promios\n\nI have a relevant scrapping experience and will be glad making this job for you.\n\nMy experience:\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years). That was exactly the bunch of jobs like we need for scrapping data from wck2.companieshouse.gov.uk \/ companycheck.co.uk.\nAnother good example is crawling Ukrainian auto sites (names are under NDA) with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nHappy New Year! ))\n\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098320",
    "openingUID": "680775165344882688",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nI propose you to make this as a chrome extension. I have a relevant experience - my job as a CTO at Periodix.net startup (2 years).\nI've created a chrome extension and server program, that allows to take any part of any site and update it on your dashboard. So, I know exactly how to implement the comparison extension that you described.\n\nThank you for any answer,\n\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098307",
    "openingUID": "693867979670843392",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nA sample screenshot of one of my crawlers is in attachment.\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years).\nhttps:\/\/periodix.net\/\n\nSome of my other previous scrappers are:\nCrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nHappy to answer any questions,\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841702528098313",
    "openingUID": "687988684260130816",
    "coverLetter": "Hello,\n\nNice meeting you.\nI'm Rinat from Ukraine. My skype ID is: promios\n\nThe job can be done in various ways, the choice depends on would you like to grab data once or on a regular basis - ?\nThe job assessment depends on how many sites would you like to scrap.\n\nMy experience:\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years).\nAnother good example is crawling Ukrainian auto sites (names are under NDA) with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098324",
    "openingUID": "694906446819389440",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years) using Phantomjs.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nSome of my other previous scrappers are:\nCrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nHappy to answer any questions,\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841702528098309",
    "openingUID": "680535384616337408",
    "coverLetter": "Hello,\n\nNice meeting you.\nMy skype ID is: promios\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841702528098318",
    "openingUID": "682552991762612224",
    "coverLetter": "Hello,\n\nNice meeting you.\nI'm Rinat from Ukraine. My skype ID is: promios\n\nAn example of UI for my last scrapper is attached. The results are downloadable in CSV format - that allows to view them in Excel or Google Docs.\n\nAs for this job, what kind of data do you mean? And what are the sources?\nKnowing this two answers, I'll be able to propose price and terms.\n\nMy experience:\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years). Another good example is crawling Ukrainian auto sites (names are under NDA) with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nHappy New Year! ))\n\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806230",
    "openingUID": "687253585035866112",
    "coverLetter": "Hello,\n\nNice meeting you.\nI'm Rinat from Ukraine. My skype ID is: promios\n\nHow many sites would you like to scrap?\n\nMy experience:\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years). Among others, it scrapped goods from e-shops.\nAnother good example is crawling Ukrainian auto sites (names are under NDA) with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806221",
    "openingUID": "689987118215585792",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nWhat site would you like to scrap?\n\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years).\nSome of my other previous scrappers are:\nCrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nHappy to answer any questions,\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841722035806233",
    "openingUID": "679693486800502784",
    "coverLetter": "Hello,\n\nNice meeting you.\n\nMy experience:\nI have a strong background in crawling sites. The most relevant is crawling Ukrainian automotive sites (names are under NDA) with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data. Another good example is crawling sites during my job as a CTO at Periodix.net startup (2 years).\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nAnother reason, why is this job important for me: I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do the job quickly and in a good quality.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806228",
    "openingUID": "686664526700613632",
    "coverLetter": "Hi Ryan,\n\nI'm Rinat from Ukraine. My skype ID is: promios\nI have a ready solution to scrap emails from Craigslist and Backpage sites. And I'm available to implement emailing proposals.\nAn example of UI for my last scrapper is attached.\n\nMore about my experience:\nI have an experience crawling sites during my job as a CTO at Periodix.net startup (2 years).\nAnother good example is crawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\n\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806212",
    "openingUID": "690746878451900416",
    "coverLetter": "Hi Jabed,\n\nThanks for the invitation. My skype is: promios\nDo you have any preferences regarding the technologies or this is on my own choice?\n\nMy task understanding: to get a renewable spreadsheet of http:\/\/iebbd.org\/MembersArea\/MembershipNoSearch.aspx \nfor the following number range:\nF 00182 \u2013 11888\nM 00112 - 35160\n- Am I right?\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841722035806229",
    "openingUID": "689908157439295488",
    "coverLetter": "Hello,\n\nAttaching yelp2csv.js, tested in Chrome console.\nMy skype id: promios\n\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nThis includes 2 years experience as a CTO at Periodix startup - scrapping various sites, including sites closed by authentication forms and stocks.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841722035806208",
    "openingUID": "690142505954828288",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\n\nPlease provide me with LinkedIn profiles \/ names so I could make a test sample.\n\nI have a relevant experience in scrapping sites and about 12 years experience in web development.\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years).\nSome of my other previous scrappers are:\nCrawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data;\nbackpage, idealist, indeed and craigslist crawling for emails;\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nHappy to answer any questions,\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841722035806211",
    "openingUID": "686711757247520768",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\nAn example of UI for my last scrapper is attached.\nI am available now and would be happy to complete this job in 3 days.\nI have a relevant experience - crawling emails based on various business directions from yell.com, google.com etc.\n\nMore about my experience:\nI have an experience crawling sites during my job as a CTO at Periodix.net startup (2 years).\nAnother good example is crawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\n\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806225",
    "openingUID": "688130088949964800",
    "coverLetter": "Hi,\n\nI'm Rinat.\nI had a relevant experience in crawling various sites at my Periodix.net startup for last 2 years as a CTO, developer & co-founder.\nI'm from Ukraine but worked in a Silicon Valley for some time during my startup activity.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nI'm about 12 years in web development. Implemented a lot of crawling and grabbing jobs.\nWould be happy to have a skype call\/chat with you. My skype ID is: promios\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806214",
    "openingUID": "687948676820766720",
    "coverLetter": "Hello,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nWould you like to grab data once or on a regular basis?\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806209",
    "openingUID": "680025926113861632",
    "coverLetter": "Hello,\n\nNice meeting you.\nI have not found the PDF, please attach it - and I will set the estimates.\nMy skype ID is: promios\n\nI have answered below about my job experience. Another reason, why is this job important for me: I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do the job quickly and in a good quality.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806231",
    "openingUID": "688068642207621120",
    "coverLetter": "Hello,\n\nMy skype id: promios\n\nI can complete this job in 12 hours.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, pass authorization forms, distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806226",
    "openingUID": "686893523264155648",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype ID is: promios\nI've recently built scrapper for craigslist & backpage (see screenshot). I can build a classified scrapper in few hours, everything depends on details. Would be happy do discuss details in skype.\n\nMore about my experience:\nI have an experience crawling sites during my job as a CTO at Periodix.net startup (2 years).\nAnother good example is crawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806234",
    "openingUID": "688059060982956032",
    "coverLetter": ""
  },
  {
    "applicationUID": "834841722035806227",
    "openingUID": "688013865486696448",
    "coverLetter": "Hello,\n\nI'm Rinat from Ukraine. My skype id is\npromios\n\nI can do this job in 24 hours. How would I do this: scrapping data from yell, craigslist, backpage and other listings. Crawlers are ready, I have only to adjust them.\n\nI have a relevant job experience: crawling emails and\/or company data based on various business directions from yell.com, google.com, craigslist.com, backpage.com etc.\nI have an experience crawling sites during my job as a CTO at Periodix.net startup (2 years).\nAnother good example is crawling Ukrainian automotive sites with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nRinat"
  },
  {
    "applicationUID": "834841722035806210",
    "openingUID": "679078825451724800",
    "coverLetter": "Hello,\n\nNice meeting you.\nMy skype ID is: promios\n\nMy experience:\nI have a strong background in crawling sites. The most relevant for this job is groupon and livingsocials crawling.\nOther good examples are crawling sites during my job as a CTO at Periodix.net startup (2 years) and crawling Ukrainian auto sites (names are under NDA) with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nAnother reason, why is this job important for me: I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do the job quickly and in a good quality.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806220",
    "openingUID": "680655864101216256",
    "coverLetter": "Hi,\n\nNice meeting you. I'm Rinat from Ukraine. My skype ID is: promios\n\nAbout my experience:\nThe most relevant experience for this project is my job as a CTO at Periodix.net startup (2 years). The project allows to take any part from any site and track it on your cloud dashboard.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nAnother reason, why is this job important for me: I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do the job quickly and in a good quality.\n\nThank you,\nAll the best,\nRinat\n"
  },
  {
    "applicationUID": "834841722035806217",
    "openingUID": "674365298537422848",
    "coverLetter": "Thank you"
  },
  {
    "applicationUID": "834841722035806213",
    "openingUID": "681204529656668160",
    "coverLetter": "Hello Patrick,\n\nThank you for the invitation. I reviewed the job post and I am available now.\n\nRinat"
  },
  {
    "applicationUID": "834841722035806216",
    "openingUID": "682594006850600960",
    "coverLetter": "Hello,\n\nNice meeting you.\nI'm Rinat from Ukraine. My skype ID is: promios\n\nAn example of UI for my last scrapper is attached. The results are downloadable in CSV format - that allows to view them in Excel or Google Docs.\n\nI am available now and would be happy to complete this job in 2-3 days.\n\nMy experience:\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years). That was exactly the bunch of jobs like we need for scraping data from wck2.companieshouse.gov.uk \/ companycheck.co.uk.\nAnother good example is crawling Ukrainian auto sites (names are under NDA) with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nHappy New Year! ))\n\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806224",
    "openingUID": "672097610929614848",
    "coverLetter": "Hi,\n\nMy relevant experience:\nI created various online tutorials before, including few variations for my startup, the latest one is:\nhttps:\/\/periodix.net\/getting-started\/\n- it's canvas-based and works on mobiles as well.\nOne more example: http:\/\/www.drapp.com.au\/pages\/demo\nI also recently created \"darkened\" tutorial like in your attachment but, unfortunately, can't show it due to the NDA.\n\nQuestions\/comments:\nCould you show or describe the steps you would like to cover in the tutorial? The budget depends on these steps...\nWhat about discussing details in skype? My skype is: promios\n\nWhy I think that this job is for me:\nThis job is simple for me, my experience in web development is good enough. I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do it quickly and in a good quality.\n\nThanks,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806222",
    "openingUID": "680487560361017344",
    "coverLetter": "Hello,\n\nNice meeting you.\nMy skype ID is: promios\n\nAbout scrapping sites... I know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nI have answered below about my job experience etc. Another reason, why is this job important for me: I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do the job quickly and in a good quality.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806235",
    "openingUID": "682551729134501888",
    "coverLetter": "Hello,\n\nNice meeting you.\nI'm Rinat from Ukraine. My skype ID is: promios\nAnd I am a scrapping expert ))\n\nAn example of UI for my last scrapper is attached. The results are downloadable in CSV format - that allows to view them in Excel or Google Docs.\n\nI am available now and would be happy to complete this job in 24 hours term.\n\nMy experience:\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years). Another good example is crawling Ukrainian auto sites (names are under NDA) with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, optimize DB queries and get rid of the duplicates, etc.\n\nThank you,\nHappy New Year! ))\n\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806219",
    "openingUID": "679759498336411648",
    "coverLetter": "I read the details\n\nHello,\n\nNice meeting you.\nMy skype ID is: promios\n\nI know how to simulate browsers and user actions and avoid bans, how to crawl js-driven and ajax-driven sites, how to distribute and optimize the load, get rid of the duplicates, etc.\n\nThe most relevant is crawling sites during my job as a CTO at Periodix.net startup (2 years). That is a Chrome extension vs server part, that particularly allowed to grab parts of amazon pages (see screenshot here https:\/\/periodix.net\/cases\/purchase )\n\nAnother good example is crawling Ukrainian auto sites (names are under NDA) with 200+ active threads in a cloud, millions of scanned pages and terabytes of processed data.\nSome of my other previous scrappers are:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking copies of some sites, including data;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nAnother reason, why is this job important for me: I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do the job quickly and in a good quality.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806223",
    "openingUID": "679994931554811904",
    "coverLetter": "Hello,\n\nNice meeting you.\nMy skype ID is: promios\n\nI have answered below about my job experience etc. Another reason, why is this job important for me: I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do the job quickly and in a good quality.\n\nThank you,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806218",
    "openingUID": "680105506870829056",
    "coverLetter": "Hi,\n\nI have a strong background in crawling sites. The most relevant is CraigsList crawling during my job as a CTO at Periodix.net startup. So, I have done more complicated things many times before.\n\nSome of my previous scrappers:\ngroupon and livingsocials crawling (company information);\ngoogle crawling (following search results, getting email databases);\nyell.com crawling to get companies contact data;\nauto portals crawling and image processing to get data for client's site;\nmaking full site copies;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nAs for your job, I can do it for $100 including installation and testing, it will take few hours. I haven't had experience with 80legs.com, but I can make it on PHP and install on your server, previously scrapping existing data from CL.\n.\nMy skype ID is: promios\n\nWhy is this job relevant for me:\nThis job is simple for me, my experience is good enough to do it. I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do it quickly and in a good quality.\n\nThanks,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806232",
    "openingUID": "672123739627294720",
    "coverLetter": "Hi,\n\nI have a great experience in crawling sites, for example:\nauto portals crawling and image processing to get data for client's site;\nyell.com crawling to get companies contact data;\ngoogle crawling (following search results, getting email databases);\nmaking full site copies;\nnews crawling to get news flows for client's sites;\njobs crawling to get data for client's job site;\netc.\n\nPlease let me know about sites you need to crawl: what sites? what kind of data? - And I'll be able to determine exact task and budget.\nMy skype is: promios\n\nWhy is this job relevant for me:\nThis job is simple for me, my experience is good enough to do it. I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do it quickly and in a good quality.\n\nThanks,\nAll the best,\nRinat"
  },
  {
    "applicationUID": "834841722035806215",
    "openingUID": "672118670866567168",
    "coverLetter": "Hi,\n\nMy relevant experience includes 8 cases of virus detection and sites recovery\/protection, for various LAMP sites.\nI'll require FTP\/SSH access to recover it effectively. We may discuss details in skype, my skype is: promios\n\nWhy is this job relevant for me:\nThis job is simple for me, my experience in web development is good enough to do it. I'm starting my work on upwork and interested in good reviews, that's why I'm interested to do it quickly and in a good quality.\n\nThanks,\nAll the best,\nRinat"
  }
]